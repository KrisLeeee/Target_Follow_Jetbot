{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from servoserial import ServoSerial\n",
    "import time\n",
    "servo_device = ServoSerial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servo_device.Servo_serial_double_control(1, 2100, 2, 2048)\n",
    "time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yes() : \n",
    "    servo_device.Servo_serial_control(2, 1600)\n",
    "    time.sleep(0.3)\n",
    "    servo_device.Servo_serial_control(2, 2048)\n",
    "    time.sleep(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no() : \n",
    "    servo_device.Servo_serial_control(1, 1700)\n",
    "    time.sleep(0.5)\n",
    "    servo_device.Servo_serial_control(1, 2500)\n",
    "    time.sleep(0.5)\n",
    "    servo_device.Servo_serial_control(1, 2100)\n",
    "    time.sleep(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "import time\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import ObjectDetector\n",
    "\n",
    "model = ObjectDetector('ssd_mobilenet_v2_coco.engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Camera\n",
    "\n",
    "#camera = Camera.instance(width=224, height=224, fps=10)\n",
    "camera = Camera.instance(width=300, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = model(camera.value)\n",
    "\n",
    "print(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "\n",
    "detections_widget = widgets.Textarea()\n",
    "detections_widget.value = str(detections)\n",
    "display(detections_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_number = 0\n",
    "object_number = 0\n",
    "\n",
    "print(detections[image_number][object_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    # Image zoomed to 224,224 versus 224,244 obstacle avoidance model\n",
    "    x = cv2.resize(x, (224, 224))\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def btch_iou(a, b, epsilon=1e-5) :\n",
    "    \n",
    "    # a : bbox of target\n",
    "    # b : bbox of other\n",
    "    \n",
    "    # 겹치는 부분의 좌표\n",
    "    x1 = np.maximum(a[0], b[:,0])\n",
    "    y1 = np.maximum(a[1], b[:,1])\n",
    "    x2 = np.minimum(a[2], b[:,2])\n",
    "    y2 = np.minimum(a[3], b[:,3])\n",
    "    \n",
    "    #겹치는 부분 길이\n",
    "    iou_width = (x2 - x1)\n",
    "    iou_height = (y2 - y1)\n",
    "    \n",
    "    # 겹치지 않을 경우\n",
    "    iou_width[iou_width < 0] = 0\n",
    "    iou_height[iou_height < 0] = 0\n",
    "    \n",
    "    # 겹치는 넓이\n",
    "    area_overlap = iou_width * iou_height\n",
    "    \n",
    "    # 전체 넓이\n",
    "    area_a = ( a[2] - a[0] ) * ( a[3] - a[1] )\n",
    "    area_b = ( b[:,2] - b[:,0] ) * ( b[:,3] - b[:,1] )\n",
    "    area_combined = area_a + area_b - area_overlap\n",
    "    \n",
    "    #IOU\n",
    "    iou = area_overlap / (area_combined + epsilon)\n",
    "    print(iou)\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import bgr8_to_jpeg\n",
    "\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "label_widget = widgets.IntText(value=1, description='tracked label')\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([image_widget]),\n",
    "    label_widget,\n",
    "]))\n",
    "\n",
    "width = int(image_widget.width)\n",
    "height = int(image_widget.height)\n",
    "\n",
    "def detection_center(detection):\n",
    "    \"\"\"Calculate the center x, y coordinates of the object\"\"\"\n",
    "    bbox = detection['bbox']\n",
    "    center_x = (bbox[0] + bbox[2]) / 2.0 - 0.5\n",
    "    center_y = (bbox[1] + bbox[3]) / 2.0 - 0.5\n",
    "    return (center_x, center_y)\n",
    "    \n",
    "def norm(vec):\n",
    "    \"\"\"Calculate the length of a two-dimensional vector\"\"\"\n",
    "    return np.sqrt(vec[0]**2 + vec[1]**2)\n",
    "\n",
    "def closest_detection(detections):\n",
    "    \"\"\"Find the detection closest to the center of the image\"\"\"\n",
    "    closest_detection = None\n",
    "    for det in detections:\n",
    "        center = detection_center(det)\n",
    "        if closest_detection is None:\n",
    "            closest_detection = det\n",
    "        elif norm(detection_center(det)) < norm(detection_center(closest_detection)):\n",
    "            closest_detection = det\n",
    "    return closest_detection\n",
    "\n",
    "\n",
    "def execute(change, target_person):\n",
    "    image = change['new']\n",
    " \n",
    "    prev_match_det = target_person # 이전 target 값 받기\n",
    "\n",
    "    # compute all detected objects\n",
    "    detections = model(image)\n",
    "    b_bbox = []\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print('현재 bbox')\n",
    "    \n",
    "    \n",
    "    # 전체 object 파란 박스로 표시하기\n",
    "    for det_bx in detections[0]:\n",
    "        bbox = det_bx['bbox']\n",
    "        label = det_bx['label']\n",
    "        confidence = det_bx['confidence']\n",
    "        cv2.putText(image, '%s, %.4f' %(label,confidence), (int(300 * bbox[0]), int(300 * bbox[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "        cv2.rectangle(image, (int(300 * bbox[0]), int(300 * bbox[1])), (int(300 * bbox[2]), int(300 * bbox[3])), (255, 0, 0), 2)\n",
    "        b_bbox.append(det_bx['bbox'])\n",
    "    \n",
    "    \n",
    "    # 새 object box 정보 저장\n",
    "    if len(b_bbox) == 0:\n",
    "        b_bbox = np.array([[0.0, 0.0, 0.0, 0.0]])\n",
    "    elif len(b_bbox) == 1:\n",
    "        b_bbox = np.array(b_bbox).reshape((1,4))\n",
    "    else:\n",
    "        b_bbox = np.array(b_bbox)\n",
    "    \n",
    "    print('b_bbox : ')\n",
    "    print(b_bbox)\n",
    "    \n",
    "    \n",
    "    # 사람이라면 목표 타겟으로 설정하기\n",
    "    matching_detections = [d for d in detections[0] if d['label'] == int(label_widget.value)]\n",
    "    \n",
    "    \n",
    "    # 이전 타겟 정보가 없을 때 det 결정\n",
    "    if prev_match_det == None:\n",
    "        print('시작!')\n",
    "        det = closest_detection(matching_detections)  # 현재 frame에서 타겟 찾기 (목표 타겟 중 가운데에 가장 가까운 것)\n",
    "        print('pmd==none : ')\n",
    "        print(det)\n",
    "        \n",
    "    # 이전 타겟 정보가 있을 때 det 결정\n",
    "    else:\n",
    "        print()\n",
    "        prev_a_bbox = prev_match_det['bbox']  # 이전 detection의 target bounding box 정보 가져오기\n",
    "        c = np.argmax(btch_iou(prev_a_bbox, b_bbox))  # 이전 target bbox와 현재 전체 bbox 중에서 iou 최대 계산\n",
    "        \n",
    "        if np.sum(b_bbox[0]) != 0 :  # 최대 iou 만드는 box가 존재\n",
    "            print('새 box 포착')\n",
    "            d = detections[0][c]  # iou 최대인 개체를 target으로 지정\n",
    "            \n",
    "            if d['label'] == int(label_widget.value): # iou 최대 개체가 사람\n",
    "                print('새 box가 사람')\n",
    "                det = d  # 새 target으로 변경\n",
    "            else:  # iou 최대 개체가 사람이 아님\n",
    "                print('새 box가 사람 아님')\n",
    "                det = prev_match_det # 이전 target 유지\n",
    "                \n",
    "            print('pmd ok / d : ')\n",
    "            print(d)               \n",
    "        \n",
    "        elif np.sum(b_bbox) == 0 : # 새 box가 없음\n",
    "            print('새 box가 없음')\n",
    "            det = prev_match_det # 이전 target 유지\n",
    "            \n",
    "        print('pmd ok / det : ')\n",
    "        print(det)\n",
    "    \n",
    "    \n",
    "    # 결정된 det를 초록색 박스로 표시\n",
    "    if det is not None:\n",
    "        bbox = det['bbox']\n",
    "        label = det['label']\n",
    "        confidence = det['confidence']\n",
    "        cv2.putText(image, '%s, %.4f' %(label,confidence), (int(300 * bbox[0]), int(300 * bbox[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        cv2.rectangle(image, (int(300 * bbox[0]), int(300 * bbox[1])), (int(300 * bbox[2]), int(300 * bbox[3])), (0, 255, 0), 4)\n",
    "        a_bbox = np.array(det['bbox'])\n",
    "        print('a_bbox : ')\n",
    "        print(a_bbox)\n",
    "\n",
    "    \n",
    "    \n",
    "    if det is None:\n",
    "        #det = prev_match_det\n",
    "        time.sleep(0.5)\n",
    "        if det is None:\n",
    "            no()\n",
    "    \n",
    "    else:\n",
    "        center = detection_center(det)\n",
    "\n",
    "\n",
    "        if label_widget.value == 1:\n",
    "            \n",
    "            servo_device.Servo_serial_double_control(1, 2100, 2, 2150)\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "            w = bbox[2] - bbox[0]\n",
    "            h = bbox[3] - bbox[1]\n",
    "            \n",
    "            # bbox 즁심을 image 중심으로 맞추기\n",
    "            if center[0] > 0.1 :\n",
    "                robot.right(0.55)\n",
    "            elif center[0] < -0.1 :\n",
    "                robot.left(0.55)\n",
    "            else :\n",
    "                # bbox 작아지면 따라가기\n",
    "                if w*h < 0.20 :\n",
    "                    robot.forward(0.55)\n",
    "                else :\n",
    "                    robot.stop()\n",
    "            \n",
    "            \n",
    "            if np.max(btch_iou(a_bbox, b_bbox)) > 0.1 :  # detections 중에서 최대 제외 iou가 일정 이상인 box가 존재하면 :\n",
    "                inst = np.argmax(btch_iou(a_bbox, b_bbox))\n",
    "                max_box = detections[0][inst]\n",
    "                max_box_center = detection_center(max_box)\n",
    "\n",
    "                if max_box['label'] == int(label_widget.value) : \n",
    "                    #무시\n",
    "                    time.sleep(0.1)\n",
    "                else :\n",
    "                    #if det['confidence'] < 0.6 :\n",
    "                    if center[0] < max_box_center[0] : # 겹치는 box center거 det center보다 오른쪽 :\n",
    "                            #왼쪽으로 갔다가 다시 오른쪽\n",
    "                        robot.set_motors(0.3, 0.7)\n",
    "                        time.sleep(0.5)\n",
    "                        robot.set_motors(0.5, 0.6)\n",
    "                        time.sleep(0.5)\n",
    "                        robot.set_motors(0.7, 0.3)\n",
    "                        time.sleep(0.5)\n",
    "                        robot.set_motors(0.6, 0.6)\n",
    "                        time.sleep(0.5)\n",
    "                        robot.stop()\n",
    "                    elif center[0] > max_box_center[0] : # 겹치는 box center가 det center보다 왼쪽 :\n",
    "                            #오른쪽으로 갔다가 다시 왼쪽\n",
    "                        robot.set_motors(0.3, 0.7)\n",
    "                        time.sleep(0.5)\n",
    "                        robot.set_motors(0.5, 0.6)\n",
    "                        time.sleep(0.5)\n",
    "                        robot.set_motors(0.7, 0.3)\n",
    "                        time.sleep(0.5)\n",
    "                        robot.set_motors(0.6, 0.6)\n",
    "                        time.sleep(0.5)\n",
    "                        robot.stop()\n",
    "                    \n",
    "                    else :\n",
    "                        #무시\n",
    "                        time.sleep(0.1)\n",
    "        \n",
    "        else :\n",
    "            time.sleep(0.5)\n",
    "            no()\n",
    "\n",
    "\n",
    "    \n",
    "        if label_widget.value != 1:\n",
    "            #det = prev_match_det\n",
    "            time.sleep(0.5)\n",
    "            no()\n",
    "\n",
    "\n",
    "    # Update image display to widget\n",
    "    image_widget.value = bgr8_to_jpeg(image)\n",
    "    \n",
    "#    prev_match_det = det\n",
    "\n",
    "    return det\n",
    "\n",
    "person = None\n",
    "person = execute({'new': camera.value}, person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#camera.unobserve_all()\n",
    "#camera.observe(execute, names='value')\n",
    "\n",
    "import threading\n",
    "import inspect\n",
    "import ctypes\n",
    "''' definition of the close thread function'''\n",
    "def _async_raise(tid, exctype):\n",
    "  \"\"\"raises the exception, performs cleanup if needed\"\"\"\n",
    "  tid = ctypes.c_long(tid)\n",
    "  if not inspect.isclass(exctype):\n",
    "    exctype = type(exctype)\n",
    "  res = ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, ctypes.py_object(exctype))\n",
    "  if res == 0:\n",
    "    raise ValueError(\"invalid thread id\")\n",
    "  elif res != 1:\n",
    "    # \"\"\"if it returns a number greater than one, you're in trouble,\n",
    "    # and you should call it again with exc=NULL to revert the effect\"\"\"\n",
    "    ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, None)\n",
    "    raise SystemError(\"PyThreadState_SetAsyncExc failed\")\n",
    "def stop_thread(thread):\n",
    "  _async_raise(thread.ident, SystemExit)\n",
    "'''The function of thread 1, which continuously calls the detection function'''\n",
    "def test():\n",
    "    person = None\n",
    "    while True:\n",
    "        person = execute({'new': camera.value}, person)        \n",
    "\n",
    "thread1 = threading.Thread(target=test)\n",
    "thread1.setDaemon(False)\n",
    "thread1.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "stop_thread(thread1)\n",
    "camera.unobserve_all()\n",
    "time.sleep(1.0)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_detections = [d for d in detections[0] if d['label'] == int(label_widget.value)]\n",
    "\n",
    "a = closest_detection(matching_detections)\n",
    "b = detections\n",
    "\n",
    "a_bbox = np.array(a['bbox'])\n",
    "b_bbox = []\n",
    "\n",
    "for det in detections[0]:\n",
    "    print(len(b_bbox))\n",
    "    b_bbox.append(det['bbox'])\n",
    "    print(len(b_bbox))\n",
    "\n",
    "bbx_size = len(b_bbox)\n",
    "    \n",
    "b_bbox = np.array(b_bbox)\n",
    "\n",
    "if bbx_size == 0:\n",
    "    b_bbox = []\n",
    "elif bbx_size == 1:\n",
    "    np.expand_dims(b_bbox, axis=0)\n",
    "\n",
    "print(detections)\n",
    "print()\n",
    "print(closest_detection(matching_detections))\n",
    "print()\n",
    "print(a_bbox)\n",
    "print()\n",
    "print(b_bbox)\n",
    "print()\n",
    "\n",
    "btch_iou(a_bbox, b_bbox)\n",
    "\n",
    "c = np.argmax(btch_iou(a_bbox, b_bbox))\n",
    "\n",
    "#print(closest_detection(matching_detections))\n",
    "print(detections[0][c])\n",
    "#print(d)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
